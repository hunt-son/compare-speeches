{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "\n",
    "ROOT_DIR = os.getcwd()\n",
    "DATA_DIR = os.path.join(ROOT_DIR, 'Raw_debates')\n",
    "RESULT_DIR = os.path.join(ROOT_DIR, 'candidate_lines')\n",
    "\n",
    "candidates = {'CLINTON', 'SANDERS', 'TRUMP', 'RUBIO', 'CRUZ'}\n",
    "cand_list = sorted(candidates)\n",
    "\n",
    "stops = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_dic = {'action': 'act',\n",
    "               'agreement': 'agree',\n",
    "               'americans': 'american',\n",
    "               'asked': 'ask',\n",
    "               'asking': 'ask',\n",
    "               'going': 'go',\n",
    "               'states': 'state',\n",
    "               'working': 'work',\n",
    "               'millions': 'million',\n",
    "               'bringing': 'bring',\n",
    "               'businesses': 'business',\n",
    "               'candidates': 'candidate',\n",
    "               'children': 'child',\n",
    "               'comes': 'come',\n",
    "               'coming': 'come',\n",
    "               'companies': 'company',\n",
    "               'countries': 'country',\n",
    "               'deals': 'deal',\n",
    "               'economic': 'economy',\n",
    "               'families': 'family',\n",
    "               'fighting': 'fight',\n",
    "               'gets': 'get',\n",
    "               'getting': 'get',\n",
    "               'goes': 'go',\n",
    "               'got': 'get',\n",
    "               'groups': 'group',\n",
    "               'guns': 'gun',\n",
    "               'happened': 'happen',\n",
    "               'happening': 'happen',\n",
    "               'helped': 'help',\n",
    "               'issues': 'issue',\n",
    "               'knows': 'know',\n",
    "               'laws': 'law',\n",
    "               'lives': 'live',\n",
    "               'living': 'live',\n",
    "               'making': 'make',\n",
    "               'needs': 'need',\n",
    "               'passed': 'pass',\n",
    "               'problems': 'problem',\n",
    "               'putting': 'put',\n",
    "               'really': 'real',\n",
    "               'republicans': 'republican',\n",
    "               'running': 'run',\n",
    "               'saying': 'say',\n",
    "               'said': 'say',\n",
    "               'seeing': 'see',\n",
    "               'seen': 'see',\n",
    "               'started': 'start',\n",
    "               'supported': 'support',\n",
    "               'taking': 'take',\n",
    "               'talked': 'talk',\n",
    "               'talking': 'talk',\n",
    "               'terrorists': 'terrorist',\n",
    "               'terrorism': 'terrorist',\n",
    "               'things': 'thing',\n",
    "               'trying': 'try',\n",
    "               'used': 'use',\n",
    "               'using': 'use',\n",
    "               'voted': 'vote',\n",
    "               'wages': 'wage',\n",
    "               'wanted': 'want',\n",
    "               'wants': 'want',\n",
    "               'building': 'build',\n",
    "               'called': 'call',\n",
    "               'came': 'come',\n",
    "               'communities': 'community',\n",
    "               'costs': 'cost',\n",
    "               'deffence': 'deffend',\n",
    "               'difference': 'different',\n",
    "               'drugs': 'drug',\n",
    "               'gave': 'give',\n",
    "               'given': 'give',\n",
    "               'gone': 'go',\n",
    "               'higher': 'high',\n",
    "               'highest': 'high',\n",
    "               'interests': 'interest',\n",
    "               'jobs': 'job',\n",
    "               'longer': 'long',\n",
    "               'looked': 'look',\n",
    "               'looking': 'look',\n",
    "               'lost': 'lose',\n",
    "               'made': 'make',\n",
    "               'means': 'mean',\n",
    "               'paying': 'pay',\n",
    "               'planned': 'plan',\n",
    "               'programs': 'program',\n",
    "               'raising': 'raise',\n",
    "               'reasons': 'reason',\n",
    "               'ringing': 'ring',\n",
    "               'says': 'say',\n",
    "               'saw': 'see',\n",
    "               'wealthy': 'wealth',\n",
    "               'worked': 'work',\n",
    "               'years': 'year'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_raw_text(cand_name):\n",
    "    file_name = '{0}.txt'.format(cand_name)\n",
    "    file_path = os.path.join(RESULT_DIR, file_name)\n",
    "    with open(file_path, 'rb') as f:\n",
    "        return f.read()\n",
    "\n",
    "def raw_to_blocks(cand_name, raw_text, delimiter='\\r\\n\\r\\n', min_len=200):\n",
    "    # Delete candidate's name\n",
    "    names_removed = raw_text.replace(cand_name + ':', '')\n",
    "    \n",
    "    # Split the text into paragraphs\n",
    "    splitted = names_removed.split(delimiter)\n",
    "\n",
    "    # Gather only long enough paragraphs\n",
    "    rets = [paragraph for paragraph in splitted if len(paragraph) > min_len]\n",
    "    return rets\n",
    "\n",
    "# Replace words that are virtually same into one word. \n",
    "def hard_code_process(text):\n",
    "    separate_word = ' {0} '\n",
    "    text = separate_word.format(text)\n",
    "    \n",
    "    for key, value in word_dic.iteritems():\n",
    "        key = separate_word.format(key)\n",
    "        value = separate_word.format(value)\n",
    "        text = text.replace(key, value)\n",
    "    return text\n",
    "\n",
    "def process_paragraph(paragraph):\n",
    "    # Remove non-letters        \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", paragraph) \n",
    "    \n",
    "    # Convert to lower case, split into individual words\n",
    "    words = letters_only.lower().split()\n",
    "    \n",
    "    # Remove stop words\n",
    "    meaningful_words = [w for w in words if not w in stops]\n",
    "    \n",
    "    rets = ' '.join(meaningful_words)\n",
    "    return hard_code_process(rets)\n",
    "\n",
    "def get_processed_lines(cand_name, delimiter='\\r\\n\\r\\n', min_len=200):\n",
    "    raw_text = get_raw_text(cand_name)\n",
    "    blocks = raw_to_blocks(cand_name, raw_text, \n",
    "                           delimiter=delimiter, min_len=min_len)\n",
    "    return map(process_paragraph, blocks)\n",
    "\n",
    "def get_vectorizer(cand_lines, max_features=1000):\n",
    "    # Initialize the \"CountVectorizer\" object, which is scikit-learn's\n",
    "    # bag of words tool.  \n",
    "    vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                                 tokenizer = None,    \\\n",
    "                                 preprocessor = None, \\\n",
    "                                 stop_words = None,   \\\n",
    "                                 max_features = max_features)\n",
    "    \n",
    "    concatenated = []\n",
    "    for cand_name, lines in cand_lines.iteritems():\n",
    "        concatenated += lines\n",
    "    \n",
    "    vectorizer.fit(concatenated)\n",
    "    return vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Examples\n",
    "cand_lines = {c: get_processed_lines(c) for c in candidates}\n",
    "vectorizer = get_vectorizer(cand_lines, 500)\n",
    "\n",
    "vocab = vectorizer.get_feature_names()\n",
    "clinton_train = vectorizer.transform(cand_lines['CLINTON']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split training data and test data\n",
    "def test_train_split(cand_lines, test_ratio=0.25):\n",
    "    cands = cand_lines.keys()\n",
    "    test_data = dict.fromkeys(cands)\n",
    "    train_data = dict.fromkeys(cands)\n",
    "    for c in cands:\n",
    "        lines = cand_lines[c]\n",
    "        l = len(lines)\n",
    "        test_len = int(l * test_ratio)\n",
    "        test_indices = set(np.random.choice(l, test_len, replace=False))\n",
    "        train_indices = set(range(l)) - test_indices\n",
    "        test_data[c] = list(np.take(lines, list(test_indices)))\n",
    "        train_data[c] = list(np.take(lines, list(train_indices)))\n",
    "    return test_data, train_data\n",
    "\n",
    "def normalize(data):\n",
    "    rets = dict()\n",
    "    for c in data:\n",
    "        d = data[c].astype(float)\n",
    "        _sum = d.sum(axis=1)\n",
    "        _sum[_sum==0] = 1\n",
    "        rets[c] = (d.T / _sum).T\n",
    "    return rets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Process the data\n",
    "\n",
    "cand_lines = {c: get_processed_lines(c) for c in candidates}\n",
    "test_data, train_data = test_train_split(cand_lines, 0.25)\n",
    "\n",
    "vectorizer = get_vectorizer(train_data, 500)\n",
    "\n",
    "for c in train_data:\n",
    "    train_data[c] = vectorizer.transform(train_data[c]).toarray()\n",
    "    test_data[c] = vectorizer.transform(test_data[c]).toarray()\n",
    "\n",
    "train_data = normalize(train_data)\n",
    "test_data = normalize(test_data)\n",
    "\n",
    "train_x, test_x = None, None\n",
    "train_y, test_y = [], []\n",
    "\n",
    "for c in train_data:\n",
    "    i  = cand_list.index(c)\n",
    "    if train_x is None:\n",
    "        train_x = train_data[c]\n",
    "    else:\n",
    "        train_x = np.concatenate((train_x, train_data[c]))\n",
    "    train_y += [i] * len(train_data[c])\n",
    "    \n",
    "for c in test_data:\n",
    "    i  = cand_list.index(c)\n",
    "    if test_x is None:\n",
    "        test_x = test_data[c]\n",
    "    else:\n",
    "        test_x = np.concatenate((test_x, test_data[c]))\n",
    "    test_y += [i] * len(test_data[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1553, 100)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Optimize C and gamma\n",
    "\n",
    "_C = []\n",
    "_gamma = []\n",
    "_train = []\n",
    "_test = []\n",
    "\n",
    "for C in [0.01, 0.1, 1, 10, 100]:\n",
    "    for gamma in [0.01, 0.1, 1, 10, 100]:\n",
    "        clf = svm.SVC(C=C, gamma=gamma)\n",
    "        clf.fit(train_x, train_y)\n",
    "        _C.append(C)\n",
    "        _gamma.append(gamma)\n",
    "        _train.append(clf.score(train_x, train_y))\n",
    "        _test.append(clf.score(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>gamma</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.211650</td>\n",
       "      <td>0.210560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.211650</td>\n",
       "      <td>0.210560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.211650</td>\n",
       "      <td>0.210560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.211650</td>\n",
       "      <td>0.210560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.211650</td>\n",
       "      <td>0.210560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.211650</td>\n",
       "      <td>0.210560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.211650</td>\n",
       "      <td>0.210560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.211650</td>\n",
       "      <td>0.210560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.10</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.322330</td>\n",
       "      <td>0.364456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.10</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.211650</td>\n",
       "      <td>0.210560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.211650</td>\n",
       "      <td>0.210560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.211650</td>\n",
       "      <td>0.210560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.642718</td>\n",
       "      <td>0.735351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.708738</td>\n",
       "      <td>0.959433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.279612</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.211650</td>\n",
       "      <td>0.210560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.652427</td>\n",
       "      <td>0.737283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.700971</td>\n",
       "      <td>0.922730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.712621</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.285437</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>100.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.650485</td>\n",
       "      <td>0.737927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>100.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.685437</td>\n",
       "      <td>0.905988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>100.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.667961</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>100.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.712621</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.285437</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         C   gamma  test_score  train_score\n",
       "0     0.01    0.01    0.211650     0.210560\n",
       "1     0.01    0.10    0.211650     0.210560\n",
       "2     0.01    1.00    0.211650     0.210560\n",
       "3     0.01   10.00    0.211650     0.210560\n",
       "4     0.01  100.00    0.211650     0.210560\n",
       "5     0.10    0.01    0.211650     0.210560\n",
       "6     0.10    0.10    0.211650     0.210560\n",
       "7     0.10    1.00    0.211650     0.210560\n",
       "8     0.10   10.00    0.322330     0.364456\n",
       "9     0.10  100.00    0.211650     0.210560\n",
       "10    1.00    0.01    0.211650     0.210560\n",
       "11    1.00    0.10    0.211650     0.210560\n",
       "12    1.00    1.00    0.642718     0.735351\n",
       "13    1.00   10.00    0.708738     0.959433\n",
       "14    1.00  100.00    0.279612     1.000000\n",
       "15   10.00    0.01    0.211650     0.210560\n",
       "16   10.00    0.10    0.652427     0.737283\n",
       "17   10.00    1.00    0.700971     0.922730\n",
       "18   10.00   10.00    0.712621     1.000000\n",
       "19   10.00  100.00    0.285437     1.000000\n",
       "20  100.00    0.01    0.650485     0.737927\n",
       "21  100.00    0.10    0.685437     0.905988\n",
       "22  100.00    1.00    0.667961     1.000000\n",
       "23  100.00   10.00    0.712621     1.000000\n",
       "24  100.00  100.00    0.285437     1.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrame({'C': _C, 'gamma': _gamma, 'train_score': _train, 'test_score': _test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'able',\n",
       " u'absolutely',\n",
       " u'across',\n",
       " u'act',\n",
       " u'actually',\n",
       " u'add',\n",
       " u'administration',\n",
       " u'advantage',\n",
       " u'affordable',\n",
       " u'african',\n",
       " u'ago',\n",
       " u'agree',\n",
       " u'air',\n",
       " u'allies',\n",
       " u'allow',\n",
       " u'almost',\n",
       " u'along',\n",
       " u'already',\n",
       " u'also',\n",
       " u'always',\n",
       " u'amendment',\n",
       " u'america',\n",
       " u'american',\n",
       " u'amnesty',\n",
       " u'another',\n",
       " u'answer',\n",
       " u'anybody',\n",
       " u'anyone',\n",
       " u'anything',\n",
       " u'applause',\n",
       " u'army',\n",
       " u'around',\n",
       " u'ask',\n",
       " u'assad',\n",
       " u'attack',\n",
       " u'attacks',\n",
       " u'away',\n",
       " u'back',\n",
       " u'bad',\n",
       " u'banks',\n",
       " u'barack',\n",
       " u'based',\n",
       " u'become',\n",
       " u'begin',\n",
       " u'behind',\n",
       " u'believe',\n",
       " u'bell',\n",
       " u'best',\n",
       " u'better',\n",
       " u'big',\n",
       " u'biggest',\n",
       " u'bill',\n",
       " u'billion',\n",
       " u'bit',\n",
       " u'border',\n",
       " u'bottom',\n",
       " u'break',\n",
       " u'bring',\n",
       " u'budget',\n",
       " u'build',\n",
       " u'built',\n",
       " u'bush',\n",
       " u'business',\n",
       " u'buy',\n",
       " u'call',\n",
       " u'campaign',\n",
       " u'candidate',\n",
       " u'cannot',\n",
       " u'care',\n",
       " u'case',\n",
       " u'century',\n",
       " u'certainly',\n",
       " u'chance',\n",
       " u'change',\n",
       " u'chief',\n",
       " u'child',\n",
       " u'china',\n",
       " u'choice',\n",
       " u'chris',\n",
       " u'city',\n",
       " u'class',\n",
       " u'clear',\n",
       " u'clinton',\n",
       " u'coalition',\n",
       " u'college',\n",
       " u'come',\n",
       " u'commander',\n",
       " u'community',\n",
       " u'company',\n",
       " u'comprehensive',\n",
       " u'congress',\n",
       " u'conservative',\n",
       " u'constitution',\n",
       " u'continue',\n",
       " u'contributions',\n",
       " u'control',\n",
       " u'corporate',\n",
       " u'cost',\n",
       " u'could',\n",
       " u'country',\n",
       " u'couple',\n",
       " u'course',\n",
       " u'court',\n",
       " u'create',\n",
       " u'credit',\n",
       " u'criminal',\n",
       " u'cut',\n",
       " u'day',\n",
       " u'deal',\n",
       " u'debate',\n",
       " u'debt',\n",
       " u'defeat',\n",
       " u'defend',\n",
       " u'defense',\n",
       " u'democracy',\n",
       " u'democratic',\n",
       " u'democrats',\n",
       " u'department',\n",
       " u'destroy',\n",
       " u'different',\n",
       " u'difficult',\n",
       " u'disagree',\n",
       " u'disaster',\n",
       " u'dodd',\n",
       " u'dollars',\n",
       " u'donald',\n",
       " u'done',\n",
       " u'drug',\n",
       " u'earth',\n",
       " u'east',\n",
       " u'economy',\n",
       " u'education',\n",
       " u'effort',\n",
       " u'eight',\n",
       " u'either',\n",
       " u'elected',\n",
       " u'election',\n",
       " u'else',\n",
       " u'end',\n",
       " u'energy',\n",
       " u'enforce',\n",
       " u'enough',\n",
       " u'entire',\n",
       " u'even',\n",
       " u'ever',\n",
       " u'every',\n",
       " u'everybody',\n",
       " u'everyone',\n",
       " u'everything',\n",
       " u'exactly',\n",
       " u'example',\n",
       " u'executive',\n",
       " u'expand',\n",
       " u'experience',\n",
       " u'face',\n",
       " u'facing',\n",
       " u'fact',\n",
       " u'fair',\n",
       " u'family',\n",
       " u'far',\n",
       " u'federal',\n",
       " u'feel',\n",
       " u'fight',\n",
       " u'figure',\n",
       " u'financial',\n",
       " u'find',\n",
       " u'first',\n",
       " u'five',\n",
       " u'flat',\n",
       " u'florida',\n",
       " u'focus',\n",
       " u'force',\n",
       " u'foreign',\n",
       " u'forward',\n",
       " u'four',\n",
       " u'frank',\n",
       " u'free',\n",
       " u'friends',\n",
       " u'funding',\n",
       " u'future',\n",
       " u'gadhafi',\n",
       " u'general',\n",
       " u'get',\n",
       " u'give',\n",
       " u'go',\n",
       " u'gonna',\n",
       " u'good',\n",
       " u'government',\n",
       " u'governor',\n",
       " u'great',\n",
       " u'greatest',\n",
       " u'ground',\n",
       " u'group',\n",
       " u'growth',\n",
       " u'gun',\n",
       " u'guy',\n",
       " u'guys',\n",
       " u'half',\n",
       " u'hampshire',\n",
       " u'hands',\n",
       " u'happen',\n",
       " u'hard',\n",
       " u'hate',\n",
       " u'health',\n",
       " u'healthcare',\n",
       " u'hear',\n",
       " u'heard',\n",
       " u'help',\n",
       " u'high',\n",
       " u'hillary',\n",
       " u'history',\n",
       " u'home',\n",
       " u'hope',\n",
       " u'hours',\n",
       " u'house',\n",
       " u'huge',\n",
       " u'hundreds',\n",
       " u'idea',\n",
       " u'illegal',\n",
       " u'illegally',\n",
       " u'immigration',\n",
       " u'important',\n",
       " u'including',\n",
       " u'income',\n",
       " u'industry',\n",
       " u'information',\n",
       " u'infrastructure',\n",
       " u'instead',\n",
       " u'insurance',\n",
       " u'intelligence',\n",
       " u'interest',\n",
       " u'involved',\n",
       " u'iowa',\n",
       " u'iran',\n",
       " u'iranian',\n",
       " u'iraq',\n",
       " u'irs',\n",
       " u'isis',\n",
       " u'islamic',\n",
       " u'israel',\n",
       " u'issue',\n",
       " u'jail',\n",
       " u'job',\n",
       " u'john',\n",
       " u'join',\n",
       " u'judgment',\n",
       " u'justice',\n",
       " u'keep',\n",
       " u'kerry',\n",
       " u'kids',\n",
       " u'kind',\n",
       " u'know',\n",
       " u'korea',\n",
       " u'last',\n",
       " u'laughter',\n",
       " u'law',\n",
       " u'lead',\n",
       " u'leadership',\n",
       " u'leave',\n",
       " u'led',\n",
       " u'left',\n",
       " u'legal',\n",
       " u'legislation',\n",
       " u'less',\n",
       " u'let',\n",
       " u'level',\n",
       " u'liberty',\n",
       " u'libya',\n",
       " u'life',\n",
       " u'like',\n",
       " u'line',\n",
       " u'listen',\n",
       " u'little',\n",
       " u'live',\n",
       " u'long',\n",
       " u'look',\n",
       " u'lose',\n",
       " u'lot',\n",
       " u'love',\n",
       " u'major',\n",
       " u'make',\n",
       " u'man',\n",
       " u'many',\n",
       " u'marco',\n",
       " u'massive',\n",
       " u'may',\n",
       " u'maybe',\n",
       " u'mean',\n",
       " u'media',\n",
       " u'men',\n",
       " u'mexico',\n",
       " u'middle',\n",
       " u'military',\n",
       " u'million',\n",
       " u'minimum',\n",
       " u'money',\n",
       " u'months',\n",
       " u'move',\n",
       " u'much',\n",
       " u'muslim',\n",
       " u'must',\n",
       " u'nation',\n",
       " u'national',\n",
       " u'need',\n",
       " u'never',\n",
       " u'new',\n",
       " u'next',\n",
       " u'nobody',\n",
       " u'north',\n",
       " u'nothing',\n",
       " u'nuclear',\n",
       " u'number',\n",
       " u'obama',\n",
       " u'obamacare',\n",
       " u'office',\n",
       " u'oil',\n",
       " u'ok',\n",
       " u'one',\n",
       " u'order',\n",
       " u'others',\n",
       " u'paid',\n",
       " u'parenthood',\n",
       " u'part',\n",
       " u'particularly',\n",
       " u'party',\n",
       " u'pass',\n",
       " u'path',\n",
       " u'pay',\n",
       " u'people',\n",
       " u'percent',\n",
       " u'person',\n",
       " u'place',\n",
       " u'plan',\n",
       " u'point',\n",
       " u'points',\n",
       " u'police',\n",
       " u'policy',\n",
       " u'political',\n",
       " u'politicians',\n",
       " u'politics',\n",
       " u'position',\n",
       " u'potential',\n",
       " u'poverty',\n",
       " u'power',\n",
       " u'powerful',\n",
       " u'president',\n",
       " u'private',\n",
       " u'probably',\n",
       " u'problem',\n",
       " u'process',\n",
       " u'program',\n",
       " u'progressive',\n",
       " u'proposal',\n",
       " u'protect',\n",
       " u'proud',\n",
       " u'provide',\n",
       " u'public',\n",
       " u'put',\n",
       " u'question',\n",
       " u'radical',\n",
       " u'raise',\n",
       " u'reach',\n",
       " u'read',\n",
       " u'reagan',\n",
       " u'real',\n",
       " u'reason',\n",
       " u'rebuild',\n",
       " u'record',\n",
       " u'reform',\n",
       " u'refugees',\n",
       " u'region',\n",
       " u'repeal',\n",
       " u'republican',\n",
       " u'respect',\n",
       " u'rest',\n",
       " u'result',\n",
       " u'rid',\n",
       " u'right',\n",
       " u'rights',\n",
       " u'ring',\n",
       " u'rings',\n",
       " u'ronald',\n",
       " u'run',\n",
       " u'russia',\n",
       " u'safe',\n",
       " u'sanders',\n",
       " u'save',\n",
       " u'say',\n",
       " u'school',\n",
       " u'second',\n",
       " u'secretary',\n",
       " u'security',\n",
       " u'see',\n",
       " u'senate',\n",
       " u'senator',\n",
       " u'set',\n",
       " u'show',\n",
       " u'side',\n",
       " u'simple',\n",
       " u'since',\n",
       " u'single',\n",
       " u'small',\n",
       " u'social',\n",
       " u'somebody',\n",
       " u'someone',\n",
       " u'something',\n",
       " u'south',\n",
       " u'special',\n",
       " u'spending',\n",
       " u'spent',\n",
       " u'st',\n",
       " u'stage',\n",
       " u'stand',\n",
       " u'standing',\n",
       " u'start',\n",
       " u'state',\n",
       " u'still',\n",
       " u'stood',\n",
       " u'stop',\n",
       " u'street',\n",
       " u'strong',\n",
       " u'super',\n",
       " u'support',\n",
       " u'supreme',\n",
       " u'sure',\n",
       " u'syria',\n",
       " u'system',\n",
       " u'take',\n",
       " u'talk',\n",
       " u'tax',\n",
       " u'taxes',\n",
       " u'ted',\n",
       " u'tell',\n",
       " u'terms',\n",
       " u'terrible',\n",
       " u'terrorist',\n",
       " u'thank',\n",
       " u'thing',\n",
       " u'think',\n",
       " u'thought',\n",
       " u'thousands',\n",
       " u'threat',\n",
       " u'three',\n",
       " u'time',\n",
       " u'times',\n",
       " u'today',\n",
       " u'together',\n",
       " u'told',\n",
       " u'tonight',\n",
       " u'took',\n",
       " u'top',\n",
       " u'trade',\n",
       " u'tremendous',\n",
       " u'trillion',\n",
       " u'troops',\n",
       " u'true',\n",
       " u'trump',\n",
       " u'trust',\n",
       " u'truth',\n",
       " u'try',\n",
       " u'tuition',\n",
       " u'turn',\n",
       " u'two',\n",
       " u'understand',\n",
       " u'united',\n",
       " u'us',\n",
       " u'use',\n",
       " u'veterans',\n",
       " u'view',\n",
       " u'vote',\n",
       " u'wage',\n",
       " u'wall',\n",
       " u'want',\n",
       " u'war',\n",
       " u'washington',\n",
       " u'way',\n",
       " u'ways',\n",
       " u'wealth',\n",
       " u'weapons',\n",
       " u'week',\n",
       " u'well',\n",
       " u'went',\n",
       " u'whether',\n",
       " u'white',\n",
       " u'whole',\n",
       " u'willing',\n",
       " u'win',\n",
       " u'without',\n",
       " u'women',\n",
       " u'word',\n",
       " u'work',\n",
       " u'workers',\n",
       " u'world',\n",
       " u'worst',\n",
       " u'would',\n",
       " u'wrong',\n",
       " u'year',\n",
       " u'yes',\n",
       " u'york',\n",
       " u'young']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
